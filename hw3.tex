\documentclass{article}
\usepackage{amsmath,amsfonts,amsthm,fancyhdr,parskip,amssymb,graphicx}
\usepackage[all]{xy}
\usepackage[margin = 1.5in]{geometry}
\pagestyle{fancy}
\lhead{Ben Carriel (bkc39)}
\chead{Bryan Cuccioli (blc72)}
\rhead{Andy Levine (awl58)}
\setlength{\parindent}{1cm}

\DeclareMathOperator{\Z}{\mathbb{Z}}
\DeclareMathOperator{\Q}{\mathbb{Q}}
\DeclareMathOperator{\R}{\mathbb{R}}
\DeclareMathOperator{\LP}{\mathrm{{\bf LP}}}

\DeclareMathOperator{\oh}{\mathcal{O}}
\DeclareMathOperator{\ta}{\xrightarrow{\ \ \ }}
\DeclareMathOperator{\opt}{\texttt{OPT}}

\newcommand{\problem}[1]{\noindent {\bf #1}}
\newcommand{\problempart}[1]{\noindent{\textbf{(#1)}}}

\newtheorem*{thm}{Theorem}
\newtheorem*{lem}{Lemma}
\newtheorem*{claim}{Claim}
\newtheorem*{defn}{Definition}
\newtheorem*{prop}{Proposition}

\begin{document}

\problem{Problem 1.}

The Ford-Fulkerson family of algorithms can be described as an instance of the simplex algorithm. Suppose we are given a network $G=(V,E)$ with source node $s\in V$ and sink $t\in V$, and edge capacity $c_{u,v}$ for each $(u,v)\in E$. We want to find
\[\max \sum_{(s,v)\in E} f(u,v)\]
subject to
\begin{enumerate}
\item $f(u,v)\leq c_{u,v}$ for all $(u,v)\in E$,
\item $f(u,v)\geq 0$ for every $(u,v)\in E$,
\item
\[\sum_{u:(u,v)\in E} f(u,v) - \sum_{w:(v,w)\in E} f(v,w) = 0\]
for every $v\in V\setminus\{s,t\}$.
\end{enumerate}

This is an LP and can be solved with the simplex algorithm. The augment step of the flow algorithm corresponds to the pivot step of the simplex algorithm. In the augment step in the flow algorithm, we are simply increasing the flow along a path until the constraint is broken at the bottleneck. In the pivot step of the simplex algorithm, we are simply increasing a variable until the constraint is broken, so it is clear that they are the same.

Furthering the analogy, when the pivots take place, the entering variable is the flow being pushed on the bottleneck edge, and the leaving variable is the flow on that edge in the residual graph, which is clear.

\problem{Problem 2.} 

\problempart{a} Here is the formulation of the multi-commodity flow problem as a linear program:
\begin{align*}
\min \sum_{e\in G} x_ep_e \\
\forall v \in G, \sum_{e = (u,v)} x_e = \sum_{e' = (v,w)} x_{e'} \\
\forall i, \sum_{e = (s_i, v)} x_e \geq C_i \\
\forall e \in G, x_e \geq 0
\end{align*}
This simply minimizes the bandwidth (first line) of all valid flows (line 2) such that each flow out of the source is large enough (line 3), and each edge has non-negative bandwidth on it (last line). 

\problempart{b}
We begin by rephrasing the LP in terms of the cuts in the graph. 
\begin{align*}
\min \sum_{e \in G} x_ep_e \\
\forall i, \forall (A,B) \text{ such that } s_i \in A, t_i \in B, \sum_{e \in A \times B} x_e \\
\forall e \in G,  x_e \geq 0
\end{align*}
The problem with this LP is that the number of cuts, and therefore the number of constraints, is exponential. To remedy this, begin by ordering the subsets of $G$, by $S = \{G_1, G_2, \ldots, G_{2^{|G|}}\}$. Then we create dual variables $y_j$ for each of the subsets $S \times S$ that correspond to a valid cut in $G$ and let $\{S_j\}_{j=1}^k$ where $k$ is the number of cuts in $G$.  
\begin{align*}
\max \sum_{e \in G} y_j \\
\forall e \in G, \sum_{e \in S_j} \frac{y_j}{\mathcal{O}(j)} \leq p_e \\
y_j \geq 0 
\end{align*}
where $\mathcal{O}(j)$ is the maximum constraint $C_i$ that is imposed on the edge $e$. We have transposed the problem in such a way that we now have exponentially many variables, but polynomially many constraints. We now seek to apply the PST framework on this revised LP. We construct an oracle as follows:
\begin{align*}
\min \sum_{e\in E} w_e \sum_{e\in S_j} \frac{y_j}{p_e}\cdot \frac{1}{\mathcal{O}(j)} \\
\min \sum_{S_j} \frac{y_j}{\mathcal{O}_j} \sum_{e \in S_j} \frac{w_e}{p_e}
\end{align*}
The goal is to use to assign weights to each edge using the above oracle in an instance of HEDGE($\epsilon$). We then have the following subroutine

\begin{enumerate}
\item UPDATE
\item assign weights $w_i$ using HEDGE($\epsilon$)
\item assign $y_j$ to maximize $w^tAy$ where we can compute $y$ by running a max-flow algorithm (Dinic's) for each cut $S_j$
\end{enumerate}
We then loop through the UPDATE step $\rho (\log (n)/\epsilon^2)$ (modification of the notes by Kleinberg where $\rho$ is some polynomial in $\sum C_i$). By the discussion in those notes, this will return a (1-$\epsilon$)-appoximation to the dual solution. We then translate this to a solution to the primal LP by translating each of the output $y_j$ to their corresponding $x_i$ values. The difficulty is that this will not be a feasible solution to the problem. Thus, we scale the problem up by the amount such that we satisfy the minimum $C_i$ constraint on each edge (this is the width as given in the problem). This gives a $(1+\epsilon)$-approximation to the primal algorithm.  

\problem{Problem 3.}

\problempart{a} Observe that if our set of constraints is linearly independent, then they span all of $\R^m$, meaning that the convex hull is unbounded. We can check if they are linearly independent by checking if the determinant of the corresponding matrix is nonzero, and this determinant can be computed in $\mathcal{O}(m^3)$.

Therefore, in the loop, we check linear independence. If it holds, we output \texttt{unbounded} and halt. Otherwise, we simply continue.

\problempart{b} In the worst case, our randomized algorithm swaps in all remaining $i$ constraints at the $n-i$ step. Therefore, for each constraint, the runtime is bounded by the sum
\[\sum_{i=1}^n \binom{n}{i} T(n-i).\]
Moreover, we have $T(n-i)<\log(n)T(n-(i+1))$, i.e. each $T(n)$ makes at most $\log(n)$ calls to the $T$ before it, so we have
\begin{align*}\sum_{i=1}^n \binom{n}{i} T(n-i)&<\sum_{i=1}^n \binom{n}{i}\log(n) T(n-(i+1))\\
&\hspace{2cm}\vdots\\
&<\sum_{i=1}^n \binom{n}{i} \prod_{j=1}^n \log(j)\\
&=\sum_{i=1}^n \binom{n}{i} \log\left(\sum_{j=1}^{n} j\right)\\
&=\sum_{i=1}^n \binom{n}{i} \log\left(\frac{n(n+1)}{2}\right)\\
&<2\sum_{i=1}^n \binom{n}{i} \log(n).\end{align*}

Moreover, we clearly have
\[\binom{n}{i}=\frac{n!}{i!(n-i)!}<\frac{(n\log n)!}{i!(n\log n - i)!} = \binom{n\log n}{i},\]
since we are adding in more factors to the numerator than the denominator. Therefore, we have
\[\sum_{i=1}^n \binom{n}{i} T(n-i) < 2\sum_{i=1}^n \binom{n\log n}{i} = 2\cdot 2^{n\log n} \in 2^{\mathcal{O}(n\log n)}.\]

Therefore, since we have in the worst case this recurrence for every $m$, the algorithm is bounded above by $2^{\mathcal{O}(n\log n)}\cdot m$.

\end{document}
